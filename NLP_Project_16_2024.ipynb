{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description and information about the project goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import string\n",
    "import spacy\n",
    "from emotion import Emotion\n",
    "import json\n",
    "from wnaffect import WNAffect\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import heapq\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1\n",
    "Add task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts all line numbers of lines in the specified topic. The topic_number argument must be given as a string. For example: '9'\n",
    "# Topic number 9 is politics\n",
    "def save_topic_lines(path_to_topic_file, topic_number):\n",
    "\n",
    "    topic_lines = []\n",
    "    topic_number = str(topic_number)\n",
    "\n",
    "    with open(path_to_topic_file, 'r') as file:\n",
    "        \n",
    "        i = 1\n",
    "\n",
    "        for line in file:\n",
    "            if line[0] == topic_number:\n",
    "                topic_lines.append(i)\n",
    "            \n",
    "            i = i + 1\n",
    "\n",
    "    return topic_lines\n",
    "\n",
    "# Extracts all dialogue lines from a specific topic\n",
    "# if topic is 'all', every topic is extracted\n",
    "def extract_topic(path_to_dialogue_file, path_to_topic_file, topic_number):\n",
    "\n",
    "    topic_lines = save_topic_lines(path_to_topic_file, topic_number)\n",
    "    topic_dialogue = []\n",
    "\n",
    "    with open(path_to_dialogue_file, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file):\n",
    "\n",
    "            if topic_number == 'all':\n",
    "                topic_dialogue.append(line)\n",
    "\n",
    "            elif topic_number != 'all':\n",
    "                if line_number in topic_lines:\n",
    "                    topic_dialogue.append(line)\n",
    "\n",
    "    return topic_dialogue\n",
    "\n",
    "# Creates a pandas dataframe for the dialogue data in a specific topic\n",
    "# Rows are dialogue lines. They are in the same order as in the original dialogues_text.txt file\n",
    "# Columns are utterances in that dialogue.\n",
    "def create_topic_dataframe(path_to_dialogue_file, path_to_topic_file, topic_number):\n",
    "\n",
    "    topic_dialogue = extract_topic(path_to_dialogue_file, path_to_topic_file, topic_number)\n",
    "\n",
    "\n",
    "    #split_dialogue = [line.split('__eou__') for line in topic_dialogue]\n",
    "\n",
    "    split_dialogue = []\n",
    "\n",
    "    for line in topic_dialogue:\n",
    "\n",
    "        split_line = line.split('__eou__')\n",
    "\n",
    "        for i in range(len(split_line)):\n",
    "            \n",
    "            if split_line[i][0] == \" \":\n",
    "\n",
    "                new_line = split_line[i][1:]\n",
    "                split_line[i] = new_line\n",
    "\n",
    "            if split_line[i][-1] == \" \":\n",
    "\n",
    "                new_line = split_line[i][:-1]\n",
    "                split_line[i] = new_line\n",
    "\n",
    "\n",
    "        split_dialogue.append(split_line)\n",
    "\n",
    "\n",
    "    topic_dialogue_data = pd.DataFrame(split_dialogue)\n",
    "\n",
    "    return topic_dialogue_data\n",
    "\n",
    "# Saves the dataframe in excel format\n",
    "# This is just for not having to write the annoying file format\n",
    "def save_dataframe_as_excel(data, filename):\n",
    "\n",
    "    if '.xlsx' not in filename:\n",
    "        filename = filename + '.xlsx'\n",
    "\n",
    "    data.to_excel(filename, header=False, index=False)\n",
    "\n",
    "# Does everything above. Extracts the topic, makes it into a dataframe and saves in excel format\n",
    "# if topic number is 'all', every topic is extracted\n",
    "def extract_and_save_topic_dialogue(path_to_dialogue_file, path_to_topic_file, topic_number, filename):\n",
    "\n",
    "    topic_dialogue_data = create_topic_dataframe(path_to_dialogue_file, path_to_topic_file, topic_number)\n",
    "    save_dataframe_as_excel(topic_dialogue_data, filename)\n",
    "\n",
    "# Give topic number and name of file to save the data. The topic number can be given as a string or an integer.\n",
    "extract_and_save_topic_dialogue('ijcnlp_dailydialog/dialogues_text.txt', 'ijcnlp_dailydialog/dialogues_topic.txt', 9, 'topic9data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data that was made with task1_save_topic.py\n",
    "def open_process_data(name_of_excel_file):\n",
    "    \n",
    "    data = pd.read_excel(name_of_excel_file)\n",
    "    rows, columns = data.shape\n",
    "    dialogues = []\n",
    "    \n",
    "    for row in range(rows):\n",
    "\n",
    "        utterances = []\n",
    "\n",
    "        for column in range(columns):\n",
    "            if type(data.iat[row, column]) is str:\n",
    "                utterances.append(data.iat[row, column])\n",
    "            \n",
    "        dialogues.append(utterances)\n",
    "\n",
    "    return dialogues\n",
    "\n",
    "# Tokenizes, lowers and removes special characters from data\n",
    "def tokenize_data(dialogues):\n",
    "    \n",
    "    special = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '=', '+', '[', ']', '{', '}', ';', ':', '\"', \"'\", '<', '>', ',', '.', '/', '?', '\\\\', '|', '`', '~', '...']\n",
    "    tokenized_dialogues = []\n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        tokenized_dialogue = []\n",
    "\n",
    "        for utterance in dialogue:\n",
    "            processed_tokenized_utterance = []\n",
    "            tokenized_utterance = word_tokenize(utterance)\n",
    "\n",
    "            for token in tokenized_utterance:\n",
    "                token.lower()\n",
    "                if (token not in special) and (len(token) != 1):\n",
    "                    processed_tokenized_utterance.append(token)\n",
    "                \n",
    "            tokenized_dialogue.append(processed_tokenized_utterance)\n",
    "        \n",
    "        tokenized_dialogues.append(tokenized_dialogue)\n",
    "    \n",
    "    return tokenized_dialogues\n",
    "\n",
    "# Calculates the vocabulary size for data. Data is given in the form that tokenize_data returns it\n",
    "def vocabulary_size(dialogues):\n",
    "    \n",
    "    tokenized_dialogues = tokenize_data(dialogues)\n",
    "    counted_words = []\n",
    "    vocabulary_size = 0\n",
    "\n",
    "    for dialogue in tokenized_dialogues:\n",
    "        for utterance in dialogue:\n",
    "            for token in utterance:\n",
    "                if token not in counted_words:\n",
    "                    vocabulary_size += 1\n",
    "                    counted_words.append(token)\n",
    "                    #print(\"Unique token: \" + token)\n",
    "\n",
    "    return vocabulary_size\n",
    "\n",
    "# Calculates the number of utterances for a dialogue\n",
    "def count_utterances(dialogues):\n",
    "\n",
    "    num_of_utterances = 0\n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        for utterance in dialogue:\n",
    "            num_of_utterances += 1\n",
    "\n",
    "    return num_of_utterances\n",
    "\n",
    "# Count average tokens per utterance for dialogue\n",
    "def count_avg_tokens_per_utterance(dialogues):\n",
    "\n",
    "    num_of_utterances = count_utterances(dialogues)\n",
    "    tokenized_dialogues = tokenize_data(dialogues)\n",
    "    total_tokens = 0\n",
    "\n",
    "    for dialogue in tokenized_dialogues:\n",
    "        for utterance in dialogue:\n",
    "            total_tokens += len(utterance)\n",
    "\n",
    "    avg_tokens_per_utterance = total_tokens / num_of_utterances\n",
    "\n",
    "    return avg_tokens_per_utterance\n",
    "\n",
    "\n",
    "# Uses NLTK part of speech tagger to identify pronouns, counts\n",
    "# the number of pronouns and then the average per utterance\n",
    "def avg_pronouns_per_utterance(dialogues):\n",
    "    \n",
    "    tokenized_dialogues = tokenize_data(dialogues)\n",
    "    pronoun_count = 0\n",
    "\n",
    "    for dialogue in tokenized_dialogues:\n",
    "        for utterance in dialogue:\n",
    "            tagged_utterance = pos_tag(utterance)\n",
    "\n",
    "            for (token, prp_tag) in tagged_utterance:\n",
    "                if prp_tag == ('PRP' or 'PRP$'):\n",
    "                    pronoun_count += 1\n",
    "\n",
    "    num_of_utterances = count_utterances(dialogues)\n",
    "    avg_prp = pronoun_count / num_of_utterances\n",
    "\n",
    "    return avg_prp\n",
    "\n",
    "\n",
    "# Didn't find any clear resource for agreement or negation wording.\n",
    "# There is nltk.metrics.agreement, but it is not for counting agreement words\n",
    "# There is also the option to try and find negation/agreement related words through wordnet, but it would also find words that are not specifially negation/agreement words\n",
    "# The custom list of agreement/negation words is subject to change\n",
    "# choice = 1 counts average number of agreement words\n",
    "# choice = 2 does the same for negation words\n",
    "def avg_agreement_negation_per_utterance(dialogues, choice):\n",
    "\n",
    "    agreement_words = ['yes', 'ok', 'sure', 'okay', 'agreed', 'agree']\n",
    "    negation_words = ['no', 'not', \"don't\", \"can't\", 'neither', ]\n",
    "\n",
    "    if choice == 1:\n",
    "        words_to_count = agreement_words\n",
    "    elif choice == 2:\n",
    "        words_to_count = negation_words\n",
    "    else:\n",
    "        print(\"Second argument: 1 for agreement words, 2 for negation words\")\n",
    "        return 0\n",
    "\n",
    "    tokenized_dialogues = tokenize_data(dialogues)\n",
    "    num_of_utterances = count_utterances(dialogues)\n",
    "    num_words_to_count = 0\n",
    "\n",
    "    for dialogue in tokenized_dialogues:\n",
    "        for utterance in dialogue:\n",
    "            for token in utterance:\n",
    "                if token in words_to_count:\n",
    "                    num_words_to_count = num_words_to_count + 1\n",
    "    \n",
    "    avg_agreement_negation = num_words_to_count / num_of_utterances\n",
    "\n",
    "    return avg_agreement_negation\n",
    "\n",
    "# Prints all stats for a given topic\n",
    "def print_stats_from_excel(name_of_excel_file):\n",
    "\n",
    "    if '.xlsx' not in name_of_excel_file:\n",
    "        name_of_excel_file = name_of_excel_file + '.xlsx'\n",
    "\n",
    "    dialogues = open_process_data(name_of_excel_file)\n",
    "    vocab = vocabulary_size(dialogues)\n",
    "    utterances = count_utterances(dialogues)\n",
    "    tokens_per_utterance = count_avg_tokens_per_utterance(dialogues)\n",
    "    avg_prp = avg_pronouns_per_utterance(dialogues)\n",
    "    avg_agreement = avg_agreement_negation_per_utterance(dialogues, 1)\n",
    "    avg_negation = avg_agreement_negation_per_utterance(dialogues, 2)\n",
    "\n",
    "    print(\"Stats for file \\\"\" + name_of_excel_file + \"\\\":\")\n",
    "    print(\"Size of vocabulary: \" + str(vocab))\n",
    "    print(\"Number of utterances: \" + str(utterances))\n",
    "    print(\"Average number of tokens per utterance: \" + str(tokens_per_utterance))\n",
    "    print(\"Average number of pronouns per utterance: \" + str(avg_prp))\n",
    "    print(\"Average number of agreement words per utterance: \" + str(avg_agreement))\n",
    "    print(\"Average number of negation words per utterance: \" + str(avg_negation))\n",
    "\n",
    "\n",
    "# Give name of the excel data file, where the dialogue data saved with previous block is stored\n",
    "print_stats_from_excel('topic9data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2\n",
    "Add task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens an excel data file saved in the format that task1_save_topic.py saves and\n",
    "# calculates the entity tags per utterance\n",
    "def avg_person_organization_entity_tags_per_utterance(excel_file_name):\n",
    "\n",
    "    if '.xlsx' not in excel_file_name:\n",
    "        excel_file_name = excel_file_name + '.xlsx'\n",
    "\n",
    "    entity_tagger = spacy.load(\"en_core_web_md\")\n",
    "    dialogues = open_process_data(excel_file_name)\n",
    "    num_entities = 0\n",
    "\n",
    "    for dialogue in dialogues:\n",
    "        for utterance in dialogue:\n",
    "            entity_tagged_utterance = entity_tagger(utterance)\n",
    "\n",
    "            for entity in entity_tagged_utterance.ents:\n",
    "                if entity.label_ == (\"ORG\" or \"PERSON\"):\n",
    "                    num_entities += 1\n",
    "\n",
    "    num_utterances = count_utterances(dialogues)\n",
    "    avg_ent_tag_per_utterance = num_entities / num_utterances\n",
    "\n",
    "    return avg_ent_tag_per_utterance\n",
    "\n",
    "# Give name of the excel data file, where the dialogue data is saved\n",
    "ent_tags_avg = avg_person_organization_entity_tags_per_utterance('topic9data')\n",
    "print(\"Average number of person/organization named-entities per utterance: \" + str(ent_tags_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 Emotion analysis using WNAffect\n",
    "\n",
    "Gives result for approaches A1 and A2 discussed in the report.\n",
    "\n",
    "In order to running this task, wordnet-1.6 and wn-domains-3.2 is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads and parses dialogues from a text file dialogues_text.txt\n",
    "# separating each utterance by __eou__ and returns a list of lists (one per dialogue).\n",
    "def get_dialogs():\n",
    "\n",
    "    with open(\"dialogues_text.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        dialogs = file.readlines()\n",
    "\n",
    "    parsed_dialogs = []\n",
    "    for dialog in dialogs:\n",
    "        d = dialog.split(\"__eou__\")\n",
    "        d = d[:-1]\n",
    "        parsed_dialogs.append(d)\n",
    "\n",
    "    return parsed_dialogs\n",
    "\n",
    "# Tokenizes each utterance and tags each word’s part of speech (POS).\n",
    "# Queries WNAffect to get emotions for each word in the utterance based on POS tags, accumulating any detected emotions in a list.\n",
    "# Returns list of emotions for utterance\n",
    "def get_emotions(utterance):\n",
    "\n",
    "    tokens = word_tokenize(utterance)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    emotions = []\n",
    "    for i in range(len(tokens)):\n",
    "        emo = wna.get_emotion(tokens[i], pos_tags[i][1])\n",
    "        if emo != None:\n",
    "            emotions.append(emo.name)\n",
    "            Emotion.printTree(Emotion.emotions[emo.name])\n",
    "            parent = emo.get_level(emo.level - 1)\n",
    "            print(\"parent: \" + parent.name)\n",
    "\n",
    "    return emotions\n",
    "\n",
    "# Calculates Accuracy, precision and recall scores for predicted WNAffect emotions.\n",
    "def validate_m(emotions):\n",
    "    \n",
    "    emotion_tags = get_emotions(get_dialogs())\n",
    "\n",
    "    emo_tags = {0: \"no emotion\", 1: \"anger\", 2: \"disgust\", 3: \"fear\", 4: \"happiness\", 5: \"sadness\", 6: \"surprise\"}\n",
    "\n",
    "    y_true = []\n",
    "    for tag in emotion_tags:\n",
    "        y_true.append(emo_tags[int(tag)])\n",
    "\n",
    "    y_pred = get_pred_class(emotions, y_true)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro', zero_division=np.nan)\n",
    "\n",
    "    print(\"Accuracy: \" + str(round(accuracy ,3)))\n",
    "    print(\"Precision: \" + str(round(precision, 3)))\n",
    "    print(\"Recall: \" + str(round(recall, 3)))\n",
    "\n",
    "# Preprocessing and prediction of the class of the emotion from WNAffect\n",
    "def get_pred_class(emotions, y_true):\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(len(emotions)):\n",
    "        if y_true[i] in emotions[i]:\n",
    "            y_pred.append(y_true[i])\n",
    "        elif len(emotions[i]) == 0:\n",
    "            y_pred.append('no emotion')\n",
    "        elif 'negative-fear' in emotions[i] or 'ambiguous-fear' in emotions[i]:\n",
    "            if y_true[i] == 'fear':\n",
    "                y_pred.append('fear')\n",
    "            else:\n",
    "                y_pred.append(emotions[i][0])\n",
    "        else:\n",
    "            y_pred.append(emotions[i][0])\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# Calls get_dialogs to load dialogues.\n",
    "# Saves emotions fro each utterance to emos.json\n",
    "def save_emotions():\n",
    "    dialogs = get_dialogs()\n",
    "\n",
    "    emotions = []\n",
    "    for dialog in dialogs:\n",
    "        dialog_emo = []\n",
    "        for utterance in dialog:\n",
    "            emo = get_emotions(utterance)\n",
    "            dialog_emo.append(emo)\n",
    "        emotions.append(dialog_emo)\n",
    "\n",
    "    with open(\"emos.json\", \"w\") as f:\n",
    "        json.dump(emotions, f, indent=4)\n",
    "\n",
    "def results_a1():\n",
    "    with open(\"emos.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    emos = []\n",
    "    for d in data:\n",
    "        for u in d:\n",
    "            emos.append(u)\n",
    "\n",
    "    validate_m(emos)\n",
    "\n",
    "def results_a2():\n",
    "    with open(\"emos_upperlevel.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    emos = []\n",
    "    for d in data:\n",
    "        for u in d:\n",
    "            emos.append(u)\n",
    "\n",
    "    validate_m(emos)\n",
    "\n",
    "wna = WNAffect('wordnet-1.6/', 'wn-domains-3.2/')\n",
    "\n",
    "# Results for approaches A1 and A2 (reference to report)\n",
    "results_a1()\n",
    "results_a2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4 Sentiment analysis with Vader sentiment analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves Vader sentiment analyser results to sentiments.json\n",
    "def save_sentiment():\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    dialogs = get_dialogs()\n",
    "\n",
    "    dialog_sentiments = []\n",
    "    for dialog in dialogs:\n",
    "        utterances = []\n",
    "        for utterance in dialog:\n",
    "            vs = analyzer.polarity_scores(utterance)\n",
    "            utterances.append(vs)\n",
    "            print(\"{:-<65} {}\".format(utterance, str(vs)))\n",
    "        dialog_sentiments.append(utterances)\n",
    "\n",
    "    with open(\"sentiments.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(dialog_sentiments, file, indent=4)\n",
    "\n",
    "# Reads sentiments.json and shows compound distribution of the results\n",
    "def results():\n",
    "\n",
    "    with open(\"sentiments.json\", 'r') as file:\n",
    "        sentiments = json.load(file)\n",
    "    \n",
    "    compounds = []\n",
    "    for dialog in sentiments:\n",
    "        for sentiment in dialog:\n",
    "            compounds.append(sentiment['compound'])\n",
    "\n",
    "    bins = np.linspace(-1,1)\n",
    "    data = compounds\n",
    "    plt.hist(data, bins=bins, edgecolor='black')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Vader sentiment analysis')\n",
    "    plt.xlabel('Compound score')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5 Correlation study between the sentiment and emotion states\n",
    "\n",
    "Prints values and shows both with none value results and without none values.\n",
    "\n",
    "In order to running this task, wordnet-1.6 and wn-domains-3.2 is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wna = WNAffect('wordnet-1.6/', 'wn-domains-3.2/')\n",
    "\n",
    "# Saves level 4 emotions (ambiguous, neutral, negative and positive) to the emos_upper_level.json file\n",
    "def save_upper_level_emotions():\n",
    "    dialogs = get_dialogs()\n",
    "\n",
    "    emotions = []\n",
    "    for dialog in dialogs:\n",
    "        dialog_emo = []\n",
    "        for utterance in dialog:\n",
    "            emo = get_emotions(utterance)\n",
    "            dialog_emo.append(emo)\n",
    "        emotions.append(dialog_emo)\n",
    "\n",
    "    with open(\"emos_upper_level.json\", \"w\") as f:\n",
    "        json.dump(emotions, f, indent=4)\n",
    "\n",
    "# Tokenizes each utterance and tags each word’s part of speech (POS).\n",
    "# Gets level 4 emotions for all emotions found with WNAffect\n",
    "def get_emotions(utterance):\n",
    "\n",
    "    tokens = word_tokenize(utterance)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    emotion_tags = []\n",
    "    for i in range(len(tokens)):\n",
    "        emo = wna.get_emotion(tokens[i], pos_tags[i][1])\n",
    "        if emo != None:\n",
    "            emotion = get_upper_level_emotion(emo)\n",
    "            emotion_tags.append(emotion)\n",
    "            # Emotion.printTree(Emotion.emotions[emo.name])\n",
    "            # parent = emo.get_level(emo.level - 1)\n",
    "            # print(\"parent: \" + parent.name)\n",
    "\n",
    "    return emotion_tags\n",
    "\n",
    "# Helper function for searching the WNAffect emotion tree to level 4\n",
    "def get_upper_level_emotion(emo):\n",
    "\n",
    "    parent = emo.get_level(emo.level - 1)\n",
    "    if emo.name == 'love':\n",
    "        for child in emo.children:\n",
    "            print(child.name)\n",
    "\n",
    "    while parent.name != \"negative-emotion\" and parent.name != \"positive-emotion\" and parent.name != \"positive-emotion\" and parent.name != \"ambiguous-emotion\" and parent.name != \"neutral-emotion\":\n",
    "        parent = emo.get_level(parent.level - 1)\n",
    "    \n",
    "    if parent.name == \"ambiguous-emotion\" or parent.name == \"neutral-emotion\":\n",
    "        return 0\n",
    "    elif parent.name == \"negative-emotion\":\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Compares level 4 emotions to Vader sentiments.\n",
    "def compare_and_save():\n",
    "\n",
    "    with open(\"emos_upper_level.json\", \"r\") as file:\n",
    "        upper_level = json.load(file)\n",
    "    \n",
    "    with open(\"sentiments.json\", \"r\") as file:\n",
    "        sentiments = json.load(file)\n",
    "\n",
    "    compared_index = []\n",
    "    for i in range(len(upper_level)):\n",
    "        dialogs = []\n",
    "        for j in range(len(upper_level[i])):\n",
    "            result = get_compared_result(sentiments[i][j][\"compound\"], upper_level[i][j])\n",
    "            dialogs.append(result)\n",
    "        compared_index.append(dialogs)\n",
    "\n",
    "    save_to_excel(compared_index, upper_level, sentiments, get_dialogs())\n",
    "\n",
    "# Saves compatibility index, emotion value, sentiment, and corresponding utterance to the excel file task5_data.xlsx \n",
    "def save_to_excel(compared_index, emotion_values, sentiments, dialogs):\n",
    "    data = {}\n",
    "    compability_index_list = []\n",
    "    emotion_values_list = []\n",
    "    sentiments_list = []\n",
    "    utterances_list = []\n",
    "    for i in range(len(compared_index)):\n",
    "        compability_index_list.extend(compared_index[i])\n",
    "        for j in range(len(compared_index[i])):\n",
    "            if len(emotion_values[i][j]) == 0:\n",
    "                emotion_values_list.append(\"None\")\n",
    "            else:\n",
    "                emotion_values_list.append(emotion_values[i][j])\n",
    "            sentiments_list.append(sentiments[i][j][\"compound\"])\n",
    "            utterances_list.append(dialogs[i][j])\n",
    "    data[\"compability index\"] = compability_index_list\n",
    "    data[\"emotion value\"] = emotion_values_list\n",
    "    data[\"sentiment\"] = sentiments_list\n",
    "    data[\"utterance\"] = utterances_list\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(\"task5_data.xlsx\", index=False)\n",
    "\n",
    "# Helper function for crating conpatibility index\n",
    "def get_compared_result(sentiment_value, emotion_values):\n",
    "    if sentiment_value >= 0.05:\n",
    "        if 1 in emotion_values:\n",
    "            if 0 not in emotion_values and -1 not in emotion_values:\n",
    "                return 1\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0\n",
    "    elif sentiment_value <= -0.05:\n",
    "        if -1 in emotion_values:\n",
    "            if 1 not in emotion_values and 0 not in emotion_values:\n",
    "                return 1\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if 0 in emotion_values:\n",
    "            if 1 not in emotion_values and -1 not in emotion_values:\n",
    "                return 1\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Results with none values\n",
    "def results():\n",
    "    df = pd.read_excel('task5_data.xlsx')\n",
    "    correlation = df['compability index']\n",
    "\n",
    "    counts = correlation.value_counts().sort_index()\n",
    "\n",
    "    print('incompatible: ', counts[0])\n",
    "    print('partial compability: ', counts[0.5])\n",
    "    print('Full compability: ', counts[1])\n",
    "\n",
    "    bin_labels = ['Incompatibility', 'Partial compatibility', 'Full compatibility']\n",
    "\n",
    "    plt.bar(bin_labels, counts, edgecolor='black')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Correlation distribution')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Results with no none values\n",
    "def results_none_removed():\n",
    "    df = pd.read_excel('task5_data.xlsx')\n",
    "    correlation = df['compability index']\n",
    "    emo_value = df['emotion value']\n",
    "\n",
    "    no_none_correlation = []\n",
    "    for i in range(len(correlation)):\n",
    "        if not pd.isna(emo_value[i]):\n",
    "            no_none_correlation.append(correlation[i])\n",
    "    \n",
    "    nncor = {}\n",
    "    nncor['compability index'] = no_none_correlation\n",
    "    df = pd.DataFrame(nncor)\n",
    "\n",
    "    counts = df['compability index'].value_counts().sort_index()\n",
    "\n",
    "    print('incompatible: ', counts[0])\n",
    "    print('partial compability: ', counts[0.5])\n",
    "    print('Full compability: ', counts[1])\n",
    "\n",
    "    bin_labels = ['Incompatibility', 'Partial compatibility', 'Full compatibility']\n",
    "\n",
    "    plt.bar(bin_labels, counts, edgecolor='black')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Correlation distribution')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "results()\n",
    "results_none_removed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6\n",
    "Add task description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens excel data and saves it into a multidimensional list\n",
    "# Use task1_save_topic.py to save topic dialogues in this excel form\n",
    "def open_process_data(name_of_data_file):\n",
    "    \n",
    "    data = pd.read_excel(name_of_data_file, header=None)\n",
    "    rows, columns = data.shape\n",
    "    dialogs = []\n",
    "\n",
    "    for row in range(rows):\n",
    "        utterances = []\n",
    "\n",
    "        for column in range(columns):\n",
    "            if (type(data.iat[row, column]) is str) & (data.iat[row, column] != \"\\n\"):\n",
    "                utterances.append(data.iat[row, column])\n",
    "            \n",
    "        dialogs.append(utterances)\n",
    "\n",
    "    return dialogs\n",
    "\n",
    "# Feature extraction function as specified in the NLTK organization book chapter 6, section 2.2\n",
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features\n",
    "\n",
    "# Trains the classifier as specified in the NLTK organization book chapter 6, section 2.2\n",
    "def train_NLTK_model():\n",
    "\n",
    "    nltk.download('nps_chat')\n",
    "    posts = nltk.corpus.nps_chat.xml_posts()[:10000]\n",
    "\n",
    "    featuresets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]\n",
    "    size = int(len(featuresets) * 0.1)\n",
    "    train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    print(\"Classifier accuracy on the NLTK NPS corpus: \" + str(nltk.classify.accuracy(classifier, test_set)))\n",
    "\n",
    "    return classifier\n",
    "\n",
    "# Classifies data from an excel file\n",
    "def classify_data(name_of_data_file):\n",
    "\n",
    "    if '.xlsx' not in name_of_data_file:\n",
    "        name_of_data_file = name_of_data_file + '.xlsx'\n",
    "\n",
    "    data = open_process_data(name_of_data_file)\n",
    "    classifier = train_NLTK_model()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for dialog in data:\n",
    "        dialog_predictions = []\n",
    "\n",
    "        for utterance in dialog:\n",
    "            utterance_features = dialogue_act_features(utterance)\n",
    "            prediction = classifier.classify(utterance_features)\n",
    "            dialog_predictions.append(prediction)\n",
    "\n",
    "        predictions.append(dialog_predictions)\n",
    "\n",
    "    return predictions\n",
    "    \n",
    "# Saves predictions\n",
    "def save_to_json(predictions, saved_file_name):\n",
    "\n",
    "    with open(saved_file_name, \"w\") as file:\n",
    "        json.dump(predictions, file, indent=4)\n",
    "\n",
    "# Give name of the excel data file, where the dialogue data is saved\n",
    "predictions = classify_data('topic9data')\n",
    "save_to_json(predictions, 'topic9data_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7\n",
    "Add task description\n",
    "Pearson correlation and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment here\n",
    "def calculate_correlations(dialogue_acts_data_file, emotions_file, sentiments_file):\n",
    "\n",
    "    with open(dialogue_acts_data_file, 'r', encoding='utf-8') as file:\n",
    "        dialogue_acts_data = json.load(file)\n",
    "\n",
    "    with open(emotions_file, 'r', encoding='utf-8') as file:\n",
    "        emotions = json.load(file)\n",
    "\n",
    "    with open(sentiments_file, 'r', encoding='utf-8') as file:\n",
    "        sentiments = json.load(file)\n",
    "\n",
    "    # The first element in the list holds a dictionary that has emotions as keys and the number of times that\n",
    "    # emotion has appeared in the same utterance for that dialogue act as values\n",
    "    # The second element in the list holds the compound sentiment and third keeps track of how many compound\n",
    "    # sentiments were added together\n",
    "    correlations = {\n",
    "        \"Emotion\": [{}, 0, 0],\n",
    "        \"yAnswer\": [{}, 0, 0],\n",
    "        #\"yAnswer\" : [{}, 0, 0],\n",
    "        \"Continuer\": [{}, 0, 0],\n",
    "        \"whQuestion\": [{}, 0, 0],\n",
    "        \"System\": [{}, 0, 0],\n",
    "        \"Accept\": [{}, 0, 0],\n",
    "        \"Clarify\": [{}, 0, 0],\n",
    "        #\"Clarity\": [{}, 0, 0],\n",
    "        \"Emphasis\": [{}, 0, 0],\n",
    "        \"nAnswer\": [{}, 0, 0],\n",
    "        \"Greet\": [{}, 0, 0],\n",
    "        \"Statement\": [{}, 0, 0],\n",
    "        \"Reject\": [{}, 0, 0],\n",
    "        \"Bye\": [{}, 0, 0],\n",
    "        \"Other\" : [{}, 0, 0],\n",
    "        #\"Others\" : [{}, 0, 0],\n",
    "        \"ynQuestion\" : [{}, 0, 0],\n",
    "    }\n",
    "\n",
    "    # Iterate over each utterance in each dialogue\n",
    "    for dialogue in range(len(dialogue_acts_data)):\n",
    "        for utterance in range(len(dialogue_acts_data[dialogue])):\n",
    "\n",
    "            \n",
    "            dialogue_act = dialogue_acts_data[dialogue][utterance]\n",
    "            sentiment = sentiments[dialogue][utterance]\n",
    "\n",
    "            # If emotions list is empty, then emotions[dialogue][utterance][0] doens't exist,\n",
    "            # but if it has an emotion, then emotions[dialogue][utterance] is a list and not a string\n",
    "            if len(emotions[dialogue][utterance]) != 0:\n",
    "                emotion = emotions[dialogue][utterance][0]\n",
    "            else:\n",
    "                emotion = 'NaN'\n",
    "\n",
    "            # Adds emotion or increments emotion value in the correlations dict lists first dictionary\n",
    "            # If emotion is not found before for this dialogue act, it is added to the dict as a key, with a value of one.\n",
    "            # Otherwise the value for that key is incremented by one\n",
    "            # If emotion is nan, do nothing\n",
    "            if emotion == 'NaN':\n",
    "                a = 1\n",
    "            elif emotion in correlations[dialogue_act][0]:\n",
    "                correlations[dialogue_act][0][emotion] += 1\n",
    "            else:\n",
    "                correlations[dialogue_act][0][emotion] = 1\n",
    "\n",
    "            # Adds compound sentiment to the correlations dict lists second element\n",
    "            correlations[dialogue_act][1] += sentiment[\"compound\"]\n",
    "            correlations[dialogue_act][2] += 1\n",
    "\n",
    "    # This list stores lists, which have two elements. First is a dialogue act, second is the emotion that dialogue act has\n",
    "    # the highest correlation with, i.e. they appear the most together\n",
    "    highest_emotion_correlations = []\n",
    "\n",
    "    for dialogue_act in correlations:\n",
    "        \n",
    "        # Get average compound sentiment\n",
    "        correlations[dialogue_act][1] = correlations[dialogue_act][1] / correlations[dialogue_act][2]\n",
    "        print(\"Compound sentiment for \" + str(dialogue_act) + \" is: \" + str(correlations[dialogue_act][1]))\n",
    "\n",
    "        # For each dialogue act, find emotion that appears the most with it\n",
    "        if len(correlations[dialogue_act][0]) != 0:\n",
    "            highest_emotion_correlations.append([dialogue_act, max(correlations[dialogue_act][0], key=correlations[dialogue_act][0].get)])\n",
    "\n",
    "    return correlations, highest_emotion_correlations\n",
    "\n",
    "# Comment here\n",
    "correlations, highest_emotion_correlations = calculate_correlations('all_dialogues_predictions.json', 'emos.json', 'sentiments.json')\n",
    "print(highest_emotion_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8 Machine learning model for emotion predictions\n",
    "\n",
    "Prints statistics and shows confusion matrices for all four machine learning models used in the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(utterance):\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    vs = analyzer.polarity_scores(utterance)\n",
    "    if vs['compound'] <= -0.05:\n",
    "        return 0\n",
    "    elif vs['compound'] >= 0.05:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_pronouns(utterance):\n",
    "\n",
    "    tokens = word_tokenize(utterance)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "\n",
    "    counter = 0\n",
    "    for pt in pos_tags:\n",
    "        if pt[1] == 'PRP' or pt[1] == 'PRP$':\n",
    "            counter += 1\n",
    "\n",
    "    return counter\n",
    "\n",
    "def get_negation(utterance):\n",
    "\n",
    "    negation_terms = ['no', 'not', 'never', 'none', 'nobody', \"don't\", \"can't\", 'neither']\n",
    "\n",
    "    tokens = word_tokenize(utterance)\n",
    "\n",
    "    counter = 0\n",
    "    for token in tokens:\n",
    "        if token in negation_terms:\n",
    "            counter += 1\n",
    "\n",
    "    return counter\n",
    "\n",
    "def get_dialogue_acts(dialogs):\n",
    "    with open('dialogues_act.txt', 'r') as file:\n",
    "        acts = file.readlines()\n",
    "    \n",
    "    act_tags = {1: 'inform', 2: 'question', 3: 'directive', 4: 'commissive' }\n",
    "\n",
    "    a = []\n",
    "    for ac in acts:\n",
    "        temp = ac.split(' ')\n",
    "        temp = temp[:-1]\n",
    "        a.append(temp)\n",
    "    \n",
    "    d_acts = []\n",
    "    i = 0\n",
    "    for dialog in dialogs:\n",
    "        if len(dialog) != len(a[i]):\n",
    "            a[i].append(0)\n",
    "        for n in a[i]:\n",
    "            d_acts.append(int(n))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return d_acts\n",
    "\n",
    "def get_utterances(dialogs):\n",
    "\n",
    "    with open(\"dialogues_emotion.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        emotion_numbers = file.readlines()\n",
    "\n",
    "    en = []\n",
    "    for e in emotion_numbers:\n",
    "        a = e.split(\" \")\n",
    "        a = a[:-1]\n",
    "        en.append(a)\n",
    "\n",
    "    utterances = []\n",
    "    emotions = []\n",
    "    i = 0\n",
    "    for dialog in dialogs:\n",
    "        if len(dialog) != len(en[i]):\n",
    "            en[i].append(0)\n",
    "        utterances.extend(dialog)\n",
    "        emotions.extend(en[i])\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return utterances, emotions\n",
    "\n",
    "def save_features():\n",
    "    dialogs = get_dialogs()\n",
    "    utterances, emotions = get_utterances(dialogs)\n",
    "    acts = get_dialogue_acts(dialogs)\n",
    "\n",
    "    # Create feature vectors\n",
    "    features = []\n",
    "    i = 0\n",
    "    for utterance in utterances:\n",
    "        utterance_feature = []\n",
    "        utterance_feature.append(get_sentiment(utterance))\n",
    "        utterance_feature.append(get_pronouns(utterance))\n",
    "        utterance_feature.append(get_negation(utterance))\n",
    "        utterance_feature.append(acts[i])\n",
    "        features.append(utterance_feature)\n",
    "        i += 1\n",
    "    \n",
    "    with open('utterance_features.json', 'w') as file:\n",
    "        json.dump(features, file, indent=4)\n",
    "\n",
    "def load_dataset():\n",
    "    dialogs = get_dialogs()\n",
    "    utterances, emotions = get_utterances(dialogs)\n",
    "\n",
    "    with open('utterance_features.json', 'r') as file:\n",
    "        features = json.load(file)\n",
    "\n",
    "    for i in range(len(emotions)):\n",
    "        emotions[i] = int(emotions[i])\n",
    "\n",
    "    counter = 0\n",
    "    i = 0\n",
    "    while counter < 65000:\n",
    "        if emotions[i] == 0:\n",
    "            emotions.pop(i)\n",
    "            utterances.pop(i)\n",
    "            features.pop(i)\n",
    "            counter += 1\n",
    "            i -= 1\n",
    "        i += 1\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(utterances).toarray()\n",
    "    X = np.hstack([X, features])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, emotions, test_size=0.2)\n",
    "\n",
    "    return X_train, X_test, y_test, y_train\n",
    "\n",
    "def multinomialNB():\n",
    "    X_train, X_test, y_test, y_train = load_dataset()\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    pr = clf.predict(X_test)\n",
    "\n",
    "    results(y_test, pr, 'Multinomial Naive Bayes')\n",
    "\n",
    "def randomForest():\n",
    "    X_train, X_test, y_test, y_train = load_dataset()\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    pr = clf.predict(X_test)\n",
    "\n",
    "    results(y_test, pr, 'Random forest classifier')\n",
    "\n",
    "def ridgeClassifier():\n",
    "    X_train, X_test, y_test, y_train = load_dataset()\n",
    "    clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    pr = clf.predict(X_test)\n",
    "\n",
    "    results(y_test, pr, 'Ridge Classifier')\n",
    "\n",
    "def svm_cl():\n",
    "    X_train, X_test, y_test, y_train = load_dataset()\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    pr = clf.predict(X_test)\n",
    "\n",
    "    results(y_test, pr, 'SVM classifier')\n",
    "\n",
    "def results(y_test, pr, title):\n",
    "    accuracy = accuracy_score(y_test, pr)\n",
    "    precision = precision_score(y_test, pr, average='macro')\n",
    "    recall = recall_score(y_test, pr, average='macro', zero_division=np.nan)\n",
    "\n",
    "    unique, counts = np.unique(pr, return_counts=True)\n",
    "    for i in range(len(counts)):\n",
    "        print('Count ' + str(unique[i]) + ' : ' + str(counts[i]))\n",
    "    print(\"Accuracy: \" + str(round(accuracy ,3)))\n",
    "    print(\"Precision: \" + str(round(precision, 3)))\n",
    "    print(\"Recall: \" + str(round(recall, 3)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, pr, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_ticklabels([\"no emotion\", \"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\"])\n",
    "    ax.yaxis.set_ticklabels([\"no emotion\", \"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "multinomialNB()\n",
    "randomForest()\n",
    "ridgeClassifier()\n",
    "svm_cl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
